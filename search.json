[{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to CONTRIBUTING.md","title":"Contributing to CONTRIBUTING.md","text":"First , thanks taking time contribute! types contributions encouraged valued. See Table Contents different ways help details project handles . Please make sure read relevant section making contribution. make lot easier us maintainers smooth experience involved. community looks forward contributions. like project, just don’t time contribute, ’s fine. easy ways support project show appreciation, also happy : - Star project - Refer project project’s readme - Mention project local meetups tell friends/colleagues - Cite packages published works","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of Contents","title":"Contributing to CONTRIBUTING.md","text":"Question Want Contribute Reporting Bugs Suggesting Enhancements First Code Contribution Improving Documentation Styleguides Commit Messages Join Project Team","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"i-have-a-question","dir":"","previous_headings":"","what":"I Have a Question","title":"Contributing to CONTRIBUTING.md","text":"want ask question, assume read available Documentation. ask question, best search existing Issues might help . case found suitable issue still need clarification, can write question issue. also advisable search internet answers first. still feel need ask question need clarification, recommend following: Open Issue. Provide much context can ’re running . Provide project platform versions , depending seems relevant. take care issue soon possible.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"i-want-to-contribute","dir":"","previous_headings":"","what":"I Want To Contribute","title":"Contributing to CONTRIBUTING.md","text":"contributing project, must agree authored 100% content, necessary rights content content contribute may provided project license.","code":""},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"before-submitting-a-bug-report","dir":"","previous_headings":"I Want To Contribute > Reporting Bugs","what":"Before Submitting a Bug Report","title":"Contributing to CONTRIBUTING.md","text":"good bug report shouldn’t leave others needing chase information. Therefore, ask investigate carefully, collect information describe issue detail report. Please complete following steps advance help us fix potential bug fast possible. Make sure using latest version. Determine bug really bug error side e.g. using incompatible environment components/versions (Make sure read documentation. looking support, might want check section). see users experienced (potentially already solved) issue , check already bug report existing bug error bug tracker. Also make sure search internet see users outside GitHub community discussed issue. Collect information bug: Stack trace (Traceback) OS, Platform Version (Windows, Linux, macOS, x86, ARM) Version interpreter, compiler, SDK, runtime environment, package manager, depending seems relevant. Possibly input output Can reliably reproduce issue? can also reproduce older versions?","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"how-do-i-submit-a-good-bug-report","dir":"","previous_headings":"I Want To Contribute > Reporting Bugs","what":"How Do I Submit a Good Bug Report?","title":"Contributing to CONTRIBUTING.md","text":"must never report security related issues, vulnerabilities bugs including sensitive information issue tracker, elsewhere public. Instead sensitive bugs must sent email robert_baker@nps.gov. use GitHub issues track bugs errors. run issue project: Open Issue. (Since can’t sure point whether bug , ask talk bug yet label issue.) Explain behavior expect actual behavior. Please provide much context possible describe reproduction steps someone else can follow recreate issue . usually includes code. good bug reports isolate problem create reduced test case. See https://gist.github.com/hadley/270442 great run create reproducible examples. Provide information collected previous section. ’s filed: project team label issue accordingly. team member try reproduce issue provided steps. reproduction steps obvious way reproduce issue, team ask steps mark issue needs-repro. Bugs needs-repro tag addressed reproduced. team able reproduce issue, marked needs-fix, well possibly tags, issue left implemented someone development team. may also address issue issue pull request, reviewed development team.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"suggesting-enhancements","dir":"","previous_headings":"I Want To Contribute","what":"Suggesting Enhancements","title":"Contributing to CONTRIBUTING.md","text":"section guides submitting enhancement including completely new features minor improvements existing functionality. Following guidelines help maintainers community understand suggestion find related suggestions.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"before-submitting-an-enhancement","dir":"","previous_headings":"I Want To Contribute > Suggesting Enhancements","what":"Before Submitting an Enhancement","title":"Contributing to CONTRIBUTING.md","text":"Make sure using latest version. Read documentation carefully find functionality already covered, maybe individual configuration. Perform search see enhancement already suggested. , add comment existing issue instead opening new one. Find whether idea fits scope aims project. ’s make strong case convince project’s developers merits feature. Keep mind want features useful majority users just small subset. ’re just targeting minority users, consider writing add-/plugin library package. Please consult developers like create add-package. Maybe can help!","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"how-do-i-submit-a-good-enhancement-suggestion","dir":"","previous_headings":"I Want To Contribute > Suggesting Enhancements","what":"How Do I Submit a Good Enhancement Suggestion?","title":"Contributing to CONTRIBUTING.md","text":"Enhancement suggestions tracked GitHub issues. Use clear descriptive title issue identify suggestion. Provide step--step description suggested enhancement many details possible. Describe current behavior explain behavior expected see instead . point can also tell alternatives work . may want include screenshots animated GIFs help demonstrate steps point part suggestion related . good free software generating GIFs across major operating systems. Explain enhancement useful users. may also want point projects solved better serve inspiration.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"your-first-code-contribution","dir":"","previous_headings":"I Want To Contribute","what":"Your First Code Contribution","title":"Contributing to CONTRIBUTING.md","text":"like contribute code please make adjustments issue pull request. development team review code prior merging pull request. issuing pull request make sure: 1) added description changes made changelog NEWS.md 2) added function, make sure also include unit tests cover function. changed function, make sure unit tests still pass. 3) added changed function, make sure package loads using devtools::load_all(). 2) updated necessary documentation using devtools::document() 3) updated associated web pages using pkgdown::build_site_github_pages() 4) checked errors warnings package built using devtools::check().","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"styleguides","dir":"","previous_headings":"","what":"Styleguides","title":"Contributing to CONTRIBUTING.md","text":"encourage use tidyverse style guide.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"commit-messages","dir":"","previous_headings":"Styleguides","what":"Commit Messages","title":"Contributing to CONTRIBUTING.md","text":"Commit messages short descriptive.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/CONTRIBUTING.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributing to CONTRIBUTING.md","text":"guide based contributing.md. Make !","code":""},{"path":"https://nationalparkservice.github.io/QCkit/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 QCkit authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"DRR Purpose and Scope","text":"Data Release Report (DRR) aimed fulfilling requirements expectations Open Science National Park Service. includes: Broad adoption open-data open--default practices. move scientific disciplines toward considering publishing data sets independently-citable scientific works. Routine assignment digital object identifiers (DOIs) datasets facilitate location, reuse, citation specific data Increased transparency reproducibility processing analysis data. Establishment peer reviewed “data journals” dedicated publishing data sets associated documentation designed facilitate reuse. Expectation science-based decisions based peer-reviewed, reproducible, open science default. Data Release Reports designed parallel external peer-reviewed scientific journals dedicated facilitate reuse reproducible scientific data, recognition primary reason IMD data collected support science-based decisions. Note publication Data Release Report Series (mandated) distinct requirements document data collection, processing, quality evaluation (mandated; see ). establishment Data Release Report Series intended facilitate encourage type reporting standard format, manner commensurate current scientific norms.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"definitions","dir":"Articles","previous_headings":"","what":"Definitions","title":"DRR Purpose and Scope","text":"Reproducibility. degree scientific information, modeling, methods analysis evaluated independent third party arrive , substantially similar, conclusion original study information, scientific assessment can repeated obtain similar results (Plesser 2017). study reproducible can take original data computer code used analyze data reproduce numerical findings study. may initially sound like trivial task experience shown ’s always easy achieve seemingly minimal standard (ASA 2017, Plesser 2017). Transparency. Full disclosure methods used obtain, process, analyze, review scientific data information products, availability data went came analysis, computer code used conduct analysis. Documenting information crucial ensure reproducibility requires, minimum, sharing analytical data sets, relevant metadata, analytical code, related software. Fitness Use. utility scientific information (case dataset) intended users intended purposes. Agencies must review communicate fitness dataset intended purpose, provide public sufficient documentation dataset allow data users determine fitness data purpose third parties may consider using . Decisions. type decisions must based publicly-available, reproducible, peer-reviewed science defined. minimum includes influential decisions, may also include decisions subject public review comment. Descriptive Reporting. policies listed consistent requirement provide documentation describes methods used collect, process, evaluate science products, including data. Note distinct (practice may significantly differ ) prescriptive documents protocols, procedures, study plans. Descriptive reporting cite describe relevant science planning documents, methods used, deviations, mitigations. total, descriptive reporting provides clear “line sight” precisely data collected, processed, evaluated. Although deviations may warrant revisions prescriptive documents, changes prescriptive documents fact meet reproducibility transparency requirements.","code":""},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"nps-requirements","dir":"Articles","previous_headings":"Policy Requirements","what":"NPS Requirements","title":"DRR Purpose and Scope","text":"DO11B-, 11B-b, OMB M-05-03 (Peer review information quality): Scientific information must appropriately reviewed prior use decision-making, regulatory processes, dissemination public, regardless media. per OMB M-05-03 “scientific information” includes factual inputs, data, models, analyses, technical information, scientific assessments related disciplines behavioral social sciences, public health medical sciences, life earth sciences, engineering, physical sciences. Methods producing information made transparent, maximum extent practicable, accurate documentation, use appropriate review, verification information quality. OMB M-19-15 (Updates Implementing Information Quality Act): Federal agencies must collect, use, disseminate information fit intended purpose. Agencies must conduct pre-dissemination review quality [scientific information] based likely use information. Quality encompasses utility, integrity, objectivity, defined follows: ) Utility – utility intended users intended purposes, b) Integrity – refers security, c) Objectivity – accurate, reliable, unbiased matter presentation substance. Agencies provide public sufficient documentation dataset released allow data users determine fitness data purpose third parties may consider using . Potential users must provided sufficient information understand… data’s strengths, weaknesses, analytical limitations, security requirements, processing options. Reproducibility requirements Influential Information. Note may determined time collection, processing, dissemination default NPS scientific activities: Analyses must disseminated sufficient descriptions data methods allow reproduced qualified third parties may want test sensitivity agency analyses. higher standard simply documenting characteristics underlying data, required information. Computer code used process data made available public analysis. context results generated, example, statistical model machine augmented learning decision support, reproducibility requires, minimum transparency specific methods, design parameters, equations algorithms, parameters, assumptions used. Reports, data, computer code used, developed, cited analysis reporting findings must made publicly available except prohibited law.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"national-park-service-guidelines","dir":"Articles","previous_headings":"Policy Requirements","what":"National Park Service Guidelines","title":"DRR Purpose and Scope","text":"Multiple policy guidance documents require use best available science decision-making Natonal Park Service (NPS). Additional requirements include: 3369 (Promoting Open Science): Defines “best available science” publicly-available, reproducible, peer reviewed. Requires decisions scientific conclusions must prioritize use publicly-available, reproducible, peer-reviewed science. Decisions conclusions based must include explanation alternative best available information. Effective 28 September 2018 transition period. 11B (Ensuring Objectivity, Utility, Integrity Information Used Disseminated National Park Service): NPS ensure information releases public utilizes management decisions developed reliable data sources provide highest quality information stage information development.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"nps-inventory-and-monitoring-requirements","dir":"Articles","previous_headings":"Policy Requirements","what":"NPS Inventory and Monitoring Requirements","title":"DRR Purpose and Scope","text":"NPS-75 (Inventory Monitoring Guidelines): annual summary report documenting condition park resources developed part annual revision parks Resource Management Plan. annual report provides mechanism reviewing making recommendations revisions [Protocol/SOPs]. [Inventory] data obtained archived park records , appropriate, report written summarizing findings. Reporting requirements per IMD directive IMD Reporting Analysis Guidance Annual Analyses Required Monitoring Protocols: Conduct annual data review address whether unexpected variability outliers, whether protocol changes additional studies may needed. Part review must assess data standards defined protocol narrative, data quality standards document quality assurance plan, document whether standards met. data available review year collected (example, data submitted lab analysis), review must conducted year data available. example, water quality quantity data typically reviewed October lab results water quality available following March, data must reviewed following October review period, .","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"implications","dir":"Articles","previous_headings":"","what":"Implications","title":"DRR Purpose and Scope","text":"data NPS IMD collects intended use supporting science-based decisions per program’s five goals, intended use planning (decisions subject public comment per NEPA requirements), means default: analytical work reproducible extent possible. Analytical work includes statistical analysis reporting data well quality control procedures data tested quality standards qualified corrected appropriate. Full reproducibility may possible cases, particularly analytical methods involve subject matter expertise make informed judgments proceed analyses. cases, decisions documented ensure transparency. IMD data published supporting documentation allow reproduction results. IMD data evaluated determine whether suitable intended use. IMD data published information fully describing data collected, processed, evaluated. data published open formats support FAIR principles (Findable, Accessible, Interoperable, Resuable).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"scope","dir":"Articles","previous_headings":"","what":"Scope","title":"DRR Purpose and Scope","text":"(NPS Inventory & Monitoring Program)","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"general-studies","dir":"Articles","previous_headings":"Scope","what":"General Studies","title":"DRR Purpose and Scope","text":"project involves collection scientific data use supporting decisions made NPS personnel. General study data may may collected based documented peer-reviewed study plans defined quality standards, cases purpose-driven resultant information evaluated suitability —prior —use decision support. data may reused secondary purposes including similar decisions locations times /portions general study data may reused contribute scientific work (observations deer browsing study may contribute inventory may used ancillary data explain monitoring observations). Workflow data collection, processing, dissemination, use general studies. Teal-colored boxes subject reproducibility requirements.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"vital-signs-monitoring","dir":"Articles","previous_headings":"Scope","what":"Vital Signs Monitoring","title":"DRR Purpose and Scope","text":"Vital signs monitoring data collected IMD park staff address specific monitoring objectives following methods designed ensure long-term comparability data. Procedures established ensure data quality standards maintained perpetuity. However, monitoring data collected long periods time dynamic systems, methods employed may differ prescribed monitoring protocols, procedures, sampling plans, deviations (resultant mitigations data) must documented. Data evaluated ensure meet prescribed standards suitable analyses designed test whether monitoring objectives met. Monitoring data may reused secondary purposes including synthesis reports condition assessments, portions monitoring data may contribute inventories. Workflow data collection, processing, dissemination, use vital sign monitoring efforts. Teal-colored boxes subject reproducibility requirements.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"inventory-studies","dir":"Articles","previous_headings":"Scope","what":"Inventory Studies","title":"DRR Purpose and Scope","text":"Inventory study data similar general study data time- area-specific efforts designed answer specific management needs well broader inventory objectives outlined project-specific study plans inventory science plans. Inventory studies typically follow well-documented data collection methods procedures, resultant data evaluated whether suitable use supporting study-specific broader inventory-level objectives. Inventory study data expected reused meet broader inventory level goals, may also support scientific work decision support. Workflow data collection, processing, dissemination, use inventory studies. Teal-colored boxes subject reproducibility requirements.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/DRR_Purpose_and_Scope.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"DRR Purpose and Scope","text":"American Statistical Association (ASA). 2017. Recommendations funding agencies supporting reproducible research. https://www.amstat.org/asa/files/pdfs/POL-ReproducibleResearchRecommendations.pdf. Plesser, H. E. 2017. Reproducibility vs. Replicability: brief history confused terminology. Front. Neuroinform. 11:76. https://doi.org/10.3389/fninf.2017.00076.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Starting-a-DRR.html","id":"drrs-background","dir":"Articles","previous_headings":"","what":"DRRs: Background","title":"Starting a DRR","text":"Purpose Scope Data Release Reports DRRs created National Park Service provide detailed descriptions valuable research datasets, including methods used collect data technical analyses supporting quality measurements. Data Release Reports focus helping others reuse data rather presenting results, testing hypotheses, presenting new interpretations -depth analyses.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Starting-a-DRR.html","id":"about-the-drr-template","dir":"Articles","previous_headings":"","what":"About the DRR Template","title":"Starting a DRR","text":"Opening new NPS DRR Template write folder current working directory contains rmarkdown (.rmd) file DRR Tempate, references.bib file bibtex references, national-park-service-DRR,csl file formatting references, sub-folder, BICY_Example example data package can used knit example DRR .docx. Upon submission publication, .docx file ingested EXstyles, converted .xml file fully formatted according NPS branding compliance 508 accessibility requirements upon final publication. goal process relieve data producers, managers, scientists burden formatting allow focus primarily content. Consequently, .docx generated publication process may visually appealing. content, however, focus production, quality, utility NPS data packages.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Starting-a-DRR.html","id":"how-to-start-a-drr","dir":"Articles","previous_headings":"","what":"How to Start a DRR","title":"Starting a DRR","text":"start DRR need data flat .csv files. quality assurance, quality control, quality flagging completed. Ideally already created process creating data package (see documentation associated R package EMLeditor data package creation). .csv files want describe DRR single folder additional .csv files (files .txt .xml ignored). folder can folder used/using create data package. Using Rstudio, open R project (Select: File > New Project…) folder .csv files. already R project (.Rproj) initiated creating data package, can use R project. Install, update (necessary), load QCkit R package. QCkit can installed either component NPSdataverse . benefits installing entire NPSdataverse upon loading NPSdataverse, automatically informed updates QCkit (constituent packages). downside installing loading NPSdataverse first time install process can lengthy (many dependencies) may hit GitHub.com API rate limit. Either installation GitHub.com requires devtools package install. Open new DRR Template. within Rstudio, select “File” drop menu. Choose “New File >” “R markdown…”. open pop-dialog box. Select “Template” right-hand list choose template labelled “NPS_DRR {QCkit}”. can change file folder name something “Untitled”, example DRR render properly. Click OK. new folder generated current working directory titled, “Untitled” (whatever name opted call ).  selecting “OK” two things happen: First, DRR Template file open . called “Untitled.Rmd” default. Second, new folder created called “Untitled” (Unless opted change default “Name:” “New R Markdown” pop , whatever name gave ). Edit DRR Template reflect data like descibe according instructions “Using DRR Template” guide. “knit” .rmd file Word done editing . Submit resulting .docx file publication (via yet---determined process).","code":"# Install the devtools package, if you don't already have it: install.packages(\"devtools\") # Install and load QCkit via NPSdataverse: devtools::install_github(\"nationalparkservice/NPSdataverse\") library(NPSdataverse) # Alternatively, install and load just QCkit: devtools::install_github(\"nationalparkservice/QCkit\") library(QCkit)"},{"path":"https://nationalparkservice.github.io/QCkit/articles/Starting-a-DRR.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Starting a DRR","text":"Knit example DRR: Assuming left “Name:” default “Untitled”, able knit DRR template example .docx submitted publication. opted change Name, need update file paths knitting.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Using the DRR Template","text":"Data Release Reports (DRRs) created National Park Service provide detailed descriptions valuable research datasets, including methods used collect data technical analyses supporting quality measurements. Data Release Reports focus helping others reuse data, rather presenting results, testing hypotheses, presenting new interpretations, methods -depth analyses. DRRs intended document processing fully-Quality-Assured data final (Quality Controlled) form reproducible transparent manner. DRRs document data collection methods quality standards used prepare review data prior release. DRRs present quality resultant data context fitness intended use. DRR cites source resultant data packages published concurrently cross-referenced. Associated data packages made publicly available exception data must protected release per NPS park-specific policies. Data packages published concurrently DRRs intended independently citable scientific works can serve basis subsequent analysis reporting NPS third parties.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"project-set-up","dir":"Articles","previous_headings":"","what":"Project Set-up","title":"Using the DRR Template","text":"set project, follow instructions Article, “Starting DRR”.","code":""},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"code-chunks","dir":"Articles","previous_headings":"Reproducible Reports","what":"Code Chunks","title":"Using the DRR Template","text":"DRR Template takes advantage rmarkdown code chunks help generate reproducible report. template includes required code chunks. code chunks need edited generate report, others edited. description code chunk DRR Template instructions () edit . addition report outline description content section, template includes four standard code chunks. YAML Header: YAML header helps format DRR. need edit YAML header. R code chunks: user_edited_parameters. series parameters used creation DRR may re-used metadata associated data package construction. need edit parameters DRR. title. title Data Release Report. report_number. optional, included publishing semi-official DRR series. Set NULL reportNumber. drr_ds_ref_id. DataStore reference ID report. 7 digits long. authorNames. list author’s names. author multiple institutional affiliations, author listed affiliation. author_affiliations. list author’s affiliations. order author affiliations must match order authors authorNames list. Note entirety affiliation enclosed single set quotations. worry indentation word wrapping. two authors affiliation, list affiliation twice. author_orcid. list ORCID iDs author format “(xxxx-xxxx-xxxx-xxxx)”. author ORCID iD, specify NA (quotes). order ORCID iDs (NAs) must correspond order authors authorNames list. author listed authorNames list, corresponding ORCID (NA) also listed . Future iterations DRR Template pull ORCID iDs metadata eventually Active Directory. See ORCID information ORCID iDs register ORCID iD. drr_abstract. abstract DRR (may distinct data package abstract). Pay careful attention non-standard characters, line breaks, carriage returns, curly-quotes. may find useful write abstract NotePad text editor word processor (Microsoft Word). Indicate line breaks space paragraphs - want - using . Abstract succinctly describe study, assay(s) performed, resulting data, reuse potential, make claims regarding new scientific findings. references allowed section. good suggested length abstracts less 250 words. data_package_ref_id. DataStore reference ID data package associated report. must least one data package. Eventually, automate importing much information metadata include ability describe multiple data packages single DRR. data_P_package_T_title. title data package. Must match title DataStore (metadata). data_package_description. short title/subtitle short description data package. Must match data package metadata. data_package_DOI_doi. Auto-generated, need edit update. data package DOI. based DataStore reference number. data_package_file_names. List file names data package. include metadata files. example, include “my_data.csv” include “my_metadata.xml”. Note: data packages contain .csv .xml files, data files .csv. data_package_file_sizes. List approximate size data file. Make sure order file sizes corresponds order file names dataPackage_fileNames. data_package_file_descript. short description corresponding data file helps distinguish data files. good guideline 10 words less. used table summary table brevity priority. already created metadata data package EML format, text found “entityDescription” element data file. setup_do_not_edit. users need edit code chunk. one code snippet loading packages; r_packages section suite packages used assist reproducible reporting. may need report, included part base recommended packages. plan perform QC part DRR construction process, can add second code snipped import necessary packages QC process . title_do_not_edit. parameters auto-generated based either EML supplied (becomes option) information ’ve already supplied “user-edited-parameters”. really need edit parameters. authors_do_not_edit. need edit chunk. writes author names, ORCID iDs, affiliations .docx document based information supplied user-edited-parameters. file_table. edit. Generates table file names, sizes, descriptions data package described DRR. data_acceptance_criteria. use standard data quality assurance flags (= accepted, AE = Accepted (estimated), R = Rejected, P = Provisional), set code chunk eval = FALSE generate custom code chunk summarize custom data flagging procedures. use standard QA flags, indicate fields data files contain flagged data. Assuming column names unique, need specify file columns . column names unique, need design summary table. Briefly describe acceptance criteria data quality flagged column order specified columns. data_column_flagging. Uses input data_acceptance_criteria generate table summarizing data quality flagging data package. set data_acceptance_criteria parameter eval = FALSE, also set data_column_flagging parameter eval = FALSE. Update first line (example points BICY_Example) point directory data . data_package_flagging. used standard QA flags data package, leave parameter eval = TRUE. use standard QA flags, set eval = FALSE design custom summary table handle custom flagging protocols. set eval = TRUE, update file path pointing data files (example, path points directory “BICY_Example”). figure1. example code chunk inserting figures. Edit re-deploy necessary include many figures require. listing. Appendix , default code listing. generate code used generating report data packages. cases, code listing required. QA/QC processes data manipulations performed elsewhere, cite code (methods references) leave “listing code chunk default settings eval=FALSE echo=FALSE. developed custom scripts, can add DataStore reference”Script” cite DRR. session_info information versions R packages used generating report. cases, need report session info (leave session-info code chunk parameters default state: eval=FALSE). Session version information necessary set “Listing” code chunk appendix eval=TRUE. case, change “session info” code chunk parameters eval=TRUE.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"editing-the-text","dir":"Articles","previous_headings":"Reproducible Reports","what":"Editing the Text","title":"Using the DRR Template","text":"following text body DRR template need edited customize data package.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"data-records","dir":"Articles","previous_headings":"Reproducible Reports > Editing the Text","what":"Data Records","title":"Using the DRR Template","text":"required section consists two subheadings: Data inputs - optional subsection used describe datasets data package based re-analysis, reorganization, re-integration prevously existing data sets. Summary datasts created - required section used explain data record associated work (instance, data package), including DOI indicating information stored. shoudl also provide overview data files formats. external data record cited. Sample text included uses r code incorporate previously specified parameters data package title, file names, DOI. code sample table summarizing contents data package (except metadata) provided.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"data-quality","dir":"Articles","previous_headings":"Reproducible Reports > Editing the Text","what":"Data Quality","title":"Using the DRR Template","text":"required section. text includes multiple suggested text elements code example table defining data flagging codes. Near future development incorporate additional optional tables summarize data quality based flags data sets.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"usage-notes","dir":"Articles","previous_headings":"Reproducible Reports > Editing the Text","what":"Usage Notes","title":"Using the DRR Template","text":"required section contain brief instructions assist researchers reuse data. may include discussion software packages (appropriate citations) suitable analysing assay data files, suggested downstream processing steps (e.g. normalization, etc.), tips integrating comparing data records datasets. Authors encouraged provide code, programs data-processing workflows may help others understand use data.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"methods","dir":"Articles","previous_headings":"Reproducible Reports > Editing the Text","what":"Methods","title":"Using the DRR Template","text":"required section cites previous methods used also detailed enough describing data production including experimental design, data acquisition assays, computational processing (e.g. normalization, QA, QC) others can understand methods without referring associated publications. Optional sub-sections within methods include: Data Collection Sampling Additional Data Sources Data Processing Code availability","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"references","dir":"Articles","previous_headings":"Reproducible Reports","what":"References","title":"Using the DRR Template","text":"required section includes full bibliographic references paper, chapter, book, data package, dataset, protocol, etc cited within DRR. item Reference section specifically cited -text well.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"automating-citations","dir":"Articles","previous_headings":"Reproducible Reports > References","what":"Automating Citations","title":"Using the DRR Template","text":"automate citations, add citation bibtex format file “references.bib”. can manually copy paste bibtex reference , can search within Rstudio. within Rstudio, make sure editing DRR rmarkdown template using “Visual” view (opposed “Source”). “Insert” drop-menu, select “@ Citation…” (shortcut: Cntrl-Shift-F8). open Graphical User Interface (GUI) tool can view citations reference.bib file well search multiple databases references, automatically insert bibtex reference references.bib file (customize unique identifier ’d like) insert -text citation DRR template. Adding Citations - Source vs. Visual editing Template access citation manager. Adding Citations - Using citation manager. reference references.bib file, using Visual view template can simply type ‘@’ symbol select reference insert text. need edit citation displayed inserting text, switch back “Source” view. bibtex citation start unique identifier; example reference supplied references.bib file unique identifier “@article{Scott1994,”. Using “Source” view Rstudio, insert reference text, combining “” symbol portion unique identifier curly bracket: @Scott1994 . full citation, properly formatted, included “References” section end rendered MS Word document. . . though also worth visually inspecting .docx citation completeness formatting.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"manual-citations","dir":"Articles","previous_headings":"Reproducible Reports > References","what":"Manual citations","title":"Using the DRR Template","text":"like format citations manually, please feel free . Make sure look References section DRR Template properly format citation type. numerous examples proper formatting . Future versions DRR enable automatic reference formatting given correctly formatted bibtex file references (.bib).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"figures","dir":"Articles","previous_headings":"Reproducible Reports","what":"Figures","title":"Using the DRR Template","text":"Figures inserted using code chunks cases figure settings can set chunk header. chunk header minimum set fig.align parameter “center” specify figure caption (fig.cap parameter). Inserting figures way ensure caption properly formatted apply copy caption figure’s “alt text” tag, making 508-compliant. example: Results :","code":"```{r fig2, echo=FALSE, out.width=\"70%\", fig.align=\"center\", fig.cap=\"Example general workflow to incude in the methods section.\"}  knitr::include_graphics(\"ProcessingWorkflow.png\") ```"},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"tables","dir":"Articles","previous_headings":"Reproducible Reports","what":"Tables","title":"Using the DRR Template","text":"Tables created using kable function. Specifying caption kable function call (opposed inline markdown text) ensure caption appropriately formatted. example: Results : Table 1. Monitoring study example Data Records table.","code":"```{r Table2, echo=FALSE} c1<-c(\"Protocol1\",\"Protocol2\",\"Protocol3\") c2<-c(\"Park Unit 1\",\"Park Unit 2\",\"Park Unit 3\") c3<-c(\"Site 1\",\"Site 2\",\"Site 3\") c4<-c(\"Date 1\",\"Date 2\",\"Date 3\") c5<-c(\"GEOXXXXX\",\"GEOXXXXX\",\"GEOXXXXX\") Table2<-data.frame(c1,c2,c3,c4,c5)  kable(Table2,        col.names=c(\"Subjects\",\"Park Units\",\"Locations\",\"Sampling Dates\",\"Data\"),       caption=\"**Table 1.** Monitoring study example Data Records table.\") %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),full_width=F) ```"},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"non-reproducible-reports","dir":"Articles","previous_headings":"","what":"Non-reproducible Reports","title":"Using the DRR Template","text":"can generate .docx document manually without ussing DRR Template. .docx, properly formatted, can ingested publication software. Assuming manually created .docx also required components information, can pass review process published. final product indistinguishable one generated using DRR Template. Manually generating .docx DRR publication suggested supported.","code":""},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"report-numbers","dir":"Articles","previous_headings":"Publishing DRRs","what":"Report Numbers","title":"Using the DRR Template","text":"data release reports associated data packages cross-referential, report numbers typically assigned early data processing quality evaluation. DataStore Reference Numbers. developing report data packages, DataStore references created early process practicable. report data packages development, activated. Report Numbers. planning publish Data Release Report official DRR number, please contact IMD Deputy Chief DataStore reference number associated DRR. Persistent Identifiers. Digital object identifiers (DOIs) assigned DRRs concurrently published data packages. DOIs resolve DataStore Reference; DOIs reserved draft reference initiated DataStore. activated publication process, including relevant review, complete. DRR DOIs format: https://doi.org/10.36967/xxxxxxx Data package DOIs format: https://doi.org/10.57830/xxxxxxx “xxxxxx” 7-digit DataStore reference number.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/articles/Using-the-DRR-Template.html","id":"liability-statements","dir":"Articles","previous_headings":"Publishing DRRs","what":"Liability Statements","title":"Using the DRR Template","text":"circumstances reports associated data packages metadata published DRR series contain disclaimers text suggests work meet scientific integrity information quality standards National Park Service. following disclaimers suitable use, depending whether data provisional final (approved certified). approved & published data sets: “Unless otherwise stated, data, metadata related materials considered satisfy quality standards relative purpose data collected. Although data associated metadata reviewed accuracy completeness approved release National Park Service Inventory Monitoring Division, warranty expressed implied made regarding display utility data purposes, computer systems, shall act distribution constitute warranty.” provisional data: “data secured National Park Service (NPS) database identified [database name] received approval release NPS Inventory Monitoring Division, provisional subject revision. data released condition neither NPS U.S. Government shall held liable damages resulting authorized unauthorized use.”","code":""},{"path":"https://nationalparkservice.github.io/QCkit/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert Baker. Author, maintainer. Judd Patterson. Author. Joe DeVivo. Author. Issac Quevedo. Author. Sarah Wright. Author. Sarah Kelso. Contributor. Amy Sherman. Contributor.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Baker R, Patterson J, DeVivo J, Quevedo , Wright S (2025). QCkit: NPS Inventory Monitoring Quality Control Toolkit. R package version 1.0.2, https://github.com/nationalparkservice/QCkit/.","code":"@Manual{,   title = {QCkit: NPS Inventory and Monitoring Quality Control Toolkit},   author = {Robert Baker and Judd Patterson and Joe DeVivo and Issac Quevedo and Sarah Wright},   year = {2025},   note = {R package version 1.0.2},   url = {https://github.com/nationalparkservice/QCkit/}, }"},{"path":"https://nationalparkservice.github.io/QCkit/index.html","id":"qckit","dir":"","previous_headings":"","what":"NPS Inventory and Monitoring Quality Control Toolkit","title":"NPS Inventory and Monitoring Quality Control Toolkit","text":"QCkit collection quality control functions munge, check, flag, correct, summarize data collected U.S. National Park Service Inventory & Monitoring Division. functions particularly useful preparing data metadata creation writing Data Release Reports, may include aspects widely applicable outside National Park Service (converting UTMs Latitude Longitude). Functions typically user generated may thoroughly tested use cases. like contribute useful functions please initiate pull request. Please request enhancements bug fixes Issues.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"NPS Inventory and Monitoring Quality Control Toolkit","text":"Stand-alone installation: QCkit also part NPSdataverse can installed along components NPSdataverse:","code":"# install.packages(\"devtools\") devtools::install_github(\"nationalparkservice/QCkit\") library(QCkit) # install.packages(\"devtools\") devtools::install_github(\"nationalparkservice/NPSdataverse\") library(NPSdataverse)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/DC_col_check.html","id":null,"dir":"Reference","previous_headings":"","what":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","title":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","text":"lifecycle::badge(\"deprecated\") DC_col_check() deprecated favor check_dc_cols() enforce consistency function naming throughout package consistent tidyverse style guides. DC_col_check checks see column names dataframe match standardized simple Darwin Core names established Taxonomic Databases Working Group","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/DC_col_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","text":"","code":"DC_col_check(working_df)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/DC_col_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","text":"working_df dataframe want run function. call, simply write working_df = \"name dataframe\".","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/DC_col_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","text":"function returns list column names fix (fitting simple Darwin Core terms, custom name formatting, data quality flagging formatting). Additionally, small summary table printed counts columns falling category (DarwinCore, Custom, DQ, Fix ).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/DC_col_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","text":"dataframe created simple DarwinCore terms, drawn Darwin Core reference guide: https://dwc.tdwg.org/terms/ last updated 07-15-2021. chosen align mostly simple Darwin Core rules: https://dwc.tdwg.org/simple/. function runs column names working dataframe see match 1. standard simple DarwinCore name 2. name pattern strings matching \"custom_\", indicating custom made column  3. name pattern strings matching \"_DQ\", indicating data quality flag. column name fit within three categories, \"Fix \" statement printed alongside column name. function counts names fitting within category prints summary table.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/DC_col_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TDWG Darwin Core Column Name Check 08-23-2022 — DC_col_check","text":"","code":"if (FALSE) { # \\dontrun{ DC_col_check(yourdataframe) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/QCkit-package.html","id":null,"dir":"Reference","previous_headings":"","what":"QCkit: NPS Inventory and Monitoring Quality Control Toolkit — QCkit-package","title":"QCkit: NPS Inventory and Monitoring Quality Control Toolkit — QCkit-package","text":"package contains set useful functions data munging, quality control, data flagging. Functions contributed multiple U.S. National Park Service staff, contractors, partners others. functions likely useful quality control NPS data may utility beyond intended functions.","code":""},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/reference/QCkit-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"QCkit: NPS Inventory and Monitoring Quality Control Toolkit — QCkit-package","text":"Maintainer: Robert Baker robert_baker@nps.gov (ORCID) Authors: Judd Patterson judd_patterson@nps.gov (ORCID) Joe DeVivo Issac Quevedo (ORCID) Sarah Wright (ORCID) contributors: Sarah Kelso (ORCID) [contributor] Amy Sherman (ORCID) [contributor]","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_dc_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","title":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","text":"check_dc_cols() checks see column names dataframe match standardized simple Darwin Core names established Taxonomic Databases Working Group","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_dc_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","text":"","code":"check_dc_cols(working_df)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_dc_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","text":"working_df dataframe want run function. call, simply write working_df = \"name dataframe\".","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_dc_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","text":"function returns list column names fix (fitting simple Darwin Core terms, custom name formatting, data quality flagging formatting). Additionally, small summary table printed counts columns falling category (DarwinCore, Custom, DQ, Fix ).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_dc_cols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","text":"dataframe created simple DarwinCore terms, drawn Darwin Core reference guide: https://dwc.tdwg.org/terms/ last updated 07-15-2021. chosen align mostly simple Darwin Core rules: https://dwc.tdwg.org/simple/. function runs column names working dataframe see match 1. standard simple DarwinCore name 2. name pattern strings matching \"custom_\", indicating custom made column  3. name pattern strings matching \"_DQ\", indicating data quality flag. column name fit within three categories, \"Fix \" statement printed alongside column name. function counts names fitting within category prints summary table.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_dc_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TDWG Darwin Core Column Name Check 08-23-2022 — check_dc_cols","text":"","code":"if (FALSE) { # \\dontrun{ check_dc_cols(yourdataframe) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_te.html","id":null,"dir":"Reference","previous_headings":"","what":"Threatened Or Endangered Species Checker Function — check_te","title":"Threatened Or Endangered Species Checker Function — check_te","text":"check_te() generates list species consider removing dataset making public matching scientific names within data set Federal Conservation List. check_te() considered helpful tool identifying federally listed endangered threatened species data. National Park park-specific Protected Data Memo outlines data restricted. Threatened endangered species often - although always - listed Memos. Additional species (state conservation lists) non-threatened non-endangered species concern biological non-biological resources may listed Memos. Consult relevant park-specific Protected Data Memo prior making decisions restricting releasing data.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_te.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threatened Or Endangered Species Checker Function — check_te","text":"","code":"check_te(x, species_col, park_code, expansion = FALSE)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_te.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Threatened Or Endangered Species Checker Function — check_te","text":"x name data frame containing species observations species_col name column within data frame containing scientific names species (genus specific epithet). park_code four letter park code. list park codes. expansion Logical. Defaults FALSE. default setting return exact matches scientific binomial (genera specific epithet) data set federal match list. Setting expansion = TRUE expand list matches return species (subspecies) match list match genera listed data set, regardless whether given species actually data set. additional column indicating whether species returned data set (\"Data\") expanded (\"Expansion\") generated.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_te.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Threatened Or Endangered Species Checker Function — check_te","text":"function returns (modified) data frame names species fall federal conservation list. resulting data frame may multiple instances given species listed multiple parks (park codes listing supplied). Technically huxtable, function identically data frame downstream purposes.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_te.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Threatened Or Endangered Species Checker Function — check_te","text":"Define species data set name, column name scientific names species, four letter park code. check_te() function downloads Federal Conservation list using IRMA odata API service matches species list list scientific names data frame. Keep mind Federal list, state list. Changes taxa names may also cause species missed. odata API service publicly available, must logged NPS VPN office use function. default, expansion = FALSE, function perform exact match taxa scientificName column federal Conservation List filter results keep species listed endangered, threatened, considered listing. scientificName column contains information binomial (genus species), matches returned. instance, Order just genus listed, matched Federal Conservation List. set expansion = TRUE, function truncate item scientificName column first word attempt extract genus name. genera listed, retained. higher-order taxa listed Family, Order, Phyla first word retained. first word (typically genus) matched just generic name species Federal Conservation List. matches, regardless listing status, retained. result given species scientificName column, species within genus Federal Conservation List returned (along federal conservation listing codes column indicating whether species actually data part expanded search).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/check_te.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Threatened Or Endangered Species Checker Function — check_te","text":"","code":"if (FALSE) { # \\dontrun{ #for individual parks: check_te(x = my_species_dataframe, species_col = \"scientificName\", park_code = \"BICY\") list<-check_te(data, \"scientificName\", \"ROMO\", expansion=TRUE) # for a list of parks: park_code<-c(\"ROMO\", \"YELL\", \"SAGU\") list<-check_te(data, \"scientificName\", park_code, expansion=TRUE) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_datetime_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert EML date/time format string to one that R can parse — convert_datetime_format","title":"Convert EML date/time format string to one that R can parse — convert_datetime_format","text":"Convert EML date/time format string one R can parse","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_datetime_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert EML date/time format string to one that R can parse — convert_datetime_format","text":"","code":"convert_datetime_format(eml_format_string, convert_z = FALSE)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_datetime_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert EML date/time format string to one that R can parse — convert_datetime_format","text":"eml_format_string character vector EML date/time format strings. function understands following codes: YYYY = four digit year, YY = two digit year, MMM = three letter month abbrev., MM = two digit month, DD = two digit day, hh HH = 24 hour time, mm = minutes, ss SS = seconds, +/-hhmm, +/-hh:mm, +/-hh = UTC offset. convert_z \"Z\" end format string (indicating UTC) replaced \"%z\"? set TRUE plan use fix_utc_offset change \"Z\" datetime strings \"+0000\".","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_datetime_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert EML date/time format string to one that R can parse — convert_datetime_format","text":"character vector date/time format strings can parsed readr strptime.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_datetime_format.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert EML date/time format string to one that R can parse — convert_datetime_format","text":"convert_datetime_format() sophisticated function. EML format string valid, happily without complaint return R format string break code. warned.  Note UTC offset formats using colon two digits parsed function, parsing datetime values strings, also need use fix_utc_offset change UTC offsets +/-hhmm format R can read.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_datetime_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert EML date/time format string to one that R can parse — convert_datetime_format","text":"","code":"convert_datetime_format(\"MM/DD/YYYY\") #> [1] \"%m/%d/%Y\" convert_datetime_format(c(\"MM/DD/YYYY\", \"YY-MM-DD\")) #> [1] \"%m/%d/%Y\" \"%y-%m-%d\""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_long_to_utm.html","id":null,"dir":"Reference","previous_headings":"","what":"Return UTM Zone — convert_long_to_utm","title":"Return UTM Zone — convert_long_to_utm","text":"convert_long_2_utm() deprecated favor get_utm_zone() new funciton name accurately reflects function . convert_long_to_utm() take longitude coordinate returns corresponding UTM zone.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_long_to_utm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return UTM Zone — convert_long_to_utm","text":"","code":"convert_long_to_utm(lon)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_long_to_utm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return UTM Zone — convert_long_to_utm","text":"lon Decimal degree longitude value","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_long_to_utm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return UTM Zone — convert_long_to_utm","text":"function returns numeric UTM zone (1 60).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_long_to_utm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return UTM Zone — convert_long_to_utm","text":"Input longitude (decimal degree) coordinate simple function returns number UTM zone point falls.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","title":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","text":"convert_utm_to_ll() superseded favor generate_ll_from_utm() support encourage including zone datum columns datasets. generate_ll_from_utm() also adds ability specify coordinate reference system lat/long coordinates, accepts column names either quoted unquoted better compatibility tidyverse piping. convert_utm_to_ll() takes dataframe UTM coordinates separate Easting Northing columns, adds additional two columns converted decimalLatitude decimalLongitude coordinates using reference coordinate system WGS84. may need turn VPN function work properly.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","text":"","code":"convert_utm_to_ll(df, EastingCol, NorthingCol, zone, datum = \"WGS84\")"},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","text":"df dataframe UTM coordinates like convert. Input name dataframe. EastingCol name Easting UTM column. Input name quotations, ie. \"EastingCol\". NorthingCol name Northing UTM column. Input name quotations, ie. \"NorthingCol\". zone UTM Zone. Input zone number quotations, ie. \"17\". datum datum used coordinate reference system coordinates. Input quotations, ie. \"WGS84\"","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","text":"function returns dataframe, mutated additional two columns decimal Longitude decimal Latitude.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","text":"Define name dataframe, easting northing columns within , UTM zone within coordinates located, reference coordinate system (datum). UTM Northing Easting columns must separate columns prior running function. datum defined, function default \"WGS84\". missing coordinates dataframe preserved, however moved end dataframe. Note parameter names snake_case instead reflect DarwinCore naming conventions.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Conversion from UTM to Latitude and Longitude — convert_utm_to_ll","text":"","code":"if (FALSE) { # \\dontrun{ convert_utm_to_ll(   df = mydataframe,   EastingCol = \"EastingCoords\",   NorthingCol = \"NorthingCoords\",   zone = \"17\",   datum = \"WGS84\" ) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/create_datastore_script.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn a GitHub release into a DataStore Script Reference — create_datastore_script","title":"Turn a GitHub release into a DataStore Script Reference — create_datastore_script","text":"Given GitHub owner (\"nationalparkservice\") public repo (\"EMLeditor\"), function uses GitHub API access latest release version GitHub generate corresponding draft Script reference DataStore. WARNING: author repo GitHub, probably one adding DataStore unless good reason. want cite GitHub release/repo need DOI, contact repo maintainer suggest use function put DataStore . searches DataStore references similar title (title repo + release tag). force = FALSE similarly titled references, function return list ask user really wants new DataStore reference generated. Assuming yes (existing DataStore references similar title force = TRUE), function : 1) download .zip latest GitHub release repo, 2) initiate draft reference DataStore, 3) give draft reference title (repo + release tag), 4) upload .zip GitHub 5) add web link release GitHub. create_datastore_script() also access keywords GitHub repo (\"Topics\") add draft references keywords. automatically set reference files links public, allow data managers edit reference, set quality \"Operational\". Unless good reason backed policy specifically includes information release, please change settings (perhaps reconsider using public github repositories). user still need go access draft Script reference DataStore fill remaining fields (accessible via API automated function) activate reference (thereby generating registering citeable DOI). Reference version older reference, user access older version indicate older version current Reference. user also manually add new Reference Project repo, desired.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/create_datastore_script.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn a GitHub release into a DataStore Script Reference — create_datastore_script","text":"","code":"create_datastore_script(   owner,   repo,   path = here::here(),   force = FALSE,   dev = FALSE )"},{"path":"https://nationalparkservice.github.io/QCkit/reference/create_datastore_script.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn a GitHub release into a DataStore Script Reference — create_datastore_script","text":"owner String. owner account GitHub repo resides. example, \"nationalparkservice\" repo String. repo release turned DataStore Script reference. example, \"EMLeditor\" path String. location release .zip GitHub downloaded (uploaded ). Defaults working directory R Project (.e. ::()). force Logical. Defaults FALSE. default status function number interactive components, searching DataStore similarly titled References asking new Reference really user wants. set TRUE, interactive components turned function proceed unless hits error. Setting force = TRUE may useful scripting purposes. dev Logical. Defaults FALSE. default status, function generates populates new draft Script reference DataStore production server. set TRUE, draft Script reference generated populated DataStore development server. Setting dev = TRUE may useful testing function without generating excessive references DataStore production server.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/create_datastore_script.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn a GitHub release into a DataStore Script Reference — create_datastore_script","text":"Invisibly returns URL DataStore draft reference created.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/create_datastore_script.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turn a GitHub release into a DataStore Script Reference — create_datastore_script","text":"","code":"if (FALSE) { # \\dontrun{ create_datastore_script(\"nationalparkservice\", \"EMLeditor\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/document_missing_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Handles multiple missing values — document_missing_values","title":"Handles multiple missing values — document_missing_values","text":"Given file name (.csv ) path, function search columns contain multiple user-specified missing value codes. column multiple missing value codes, missing values (including blanks) replaced NA. new column generated , populated given missing value code origin column. Values missing populated \"not_missing\". newly generate column categorical variables can used describe various/multiple reasons data absent original column. function write new dataframe file, overwriting original file. important keep copy original file, make copy prior running function. WARNING: function replace blank cells data NA!","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/document_missing_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handles multiple missing values — document_missing_values","text":"","code":"document_missing_values(   file_name,   directory = here::here(),   colname = NA,   missing_val_codes = NA,   replace_value = NA )"},{"path":"https://nationalparkservice.github.io/QCkit/reference/document_missing_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handles multiple missing values — document_missing_values","text":"file_name String. name file inspect directory String. Location file read/write. Defaults current working directory. colname String. columns inspect. CURRENTLY WORKS SET DEFAULT \"NA\". missing_val_codes List. list strings containing missing value code codes search . replace_value String. value (singular) replace multiple missing values . Defaults NA.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/document_missing_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handles multiple missing values — document_missing_values","text":"writes new dataframe file. Return invisible.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/document_missing_values.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Handles multiple missing values — document_missing_values","text":"Blank cells treated NA.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/document_missing_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Handles multiple missing values — document_missing_values","text":"","code":"if (FALSE) { # \\dontrun{ document_missing_values(file_name = \"mydata.csv\",                         directory = here::here(),                         colname = NA, #do not change during function development                         missing_val_codes = c(\"missing\", \"blank\", \"no data\"),                         replace_value = NA)                         } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/fix_utc_offset.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix UTC offset strings — fix_utc_offset","title":"Fix UTC offset strings — fix_utc_offset","text":"UTC offsets can formatted multiple ways (e.g. -07, -07:00, -0700) R often struggles parse offsets. function takes date/time strings valid UTC offsets, formats consistent readable R. , can supply vector dates ISO 8601 format returned consistent format compatible R. Date strings missing invalid UTC offsets result warning.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fix_utc_offset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix UTC offset strings — fix_utc_offset","text":"","code":"fix_utc_offset(datetime_strings)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/fix_utc_offset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix UTC offset strings — fix_utc_offset","text":"datetime_strings Character vector dates ISO 8601 format","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fix_utc_offset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix UTC offset strings — fix_utc_offset","text":"datetime_strings UTC offsets consistently formatted four digits (e.g. \"2023-11-16T03:32:49-0700\").","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fix_utc_offset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fix UTC offset strings — fix_utc_offset","text":"","code":"datetimes <- c(\"2023-11-16T03:32:49+07:00\", \"2023-11-16T03:32:49-07\", \"2023-11-16T03:32:49\",\"2023-11-16T03:32:49Z\") fix_utc_offset(datetimes) #> Warning: Date strings contain missing or invalid UTC offsets #> [1] \"2023-11-16T03:32:49+0700\" \"2023-11-16T03:32:49-0700\" #> [3] \"2023-11-16T03:32:49\"      \"2023-11-16T03:32:49+0000\""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fuzz_location.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Coordinates Into a Polygon to Obscure Specific Location — fuzz_location","title":"Convert Coordinates Into a Polygon to Obscure Specific Location — fuzz_location","text":"fuzz_location() \"fuzzes\" specific location something less precise prior public release information sensitive resources data released public. function takes coordinates either UTM decimal degrees, converts UTM (decimal degrees), creates bounding box based rounding UTM coordinates, creates polygon resultant points. function returns string Well-Known-Text format.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fuzz_location.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Coordinates Into a Polygon to Obscure Specific Location — fuzz_location","text":"","code":"fuzz_location(lat, lon, coord_ref_sys = 4326, fuzz_level = \"Fuzzed - 1km\")"},{"path":"https://nationalparkservice.github.io/QCkit/reference/fuzz_location.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Coordinates Into a Polygon to Obscure Specific Location — fuzz_location","text":"lat latitude either UTMs decimal degrees. lon longitude either UTMs decimal degrees coord_ref_sys EPSG coordinate system latitude longitude coordinates. Either 4326 decimal degrees/WGS84 datum, 4269 decimal degrees/NAD83, 326xx UTM/WGS84 datum (xx northern UTM zone). example 32616 UTM zone 16N. fuzz_level Use \"Fuzzed - 10km\", \"Fuzzed - 1km\", \"Fuzzed - 100m\"","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fuzz_location.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Coordinates Into a Polygon to Obscure Specific Location — fuzz_location","text":"Details defined later.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/fuzz_location.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Coordinates Into a Polygon to Obscure Specific Location — fuzz_location","text":"","code":"if (FALSE) { # \\dontrun{ fuzz_location(703977, 4035059, 32616, \"Fuzzed - 1km\") fuzz_location(36.43909, -84.72429, 4326, \"Fuzzed - 1km\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/generate_ll_from_utm.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","title":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","text":"generate_ll_from_utm() takes dataframe UTM coordinates separate Easting Northing columns, adds additional two columns converted decimalLatitude decimalLongitude coordinates using reference coordinate system NAD83. data must also contain columns specifying zone datum UTM coordinates. contrast convert_utm_to_ll() (superseded), generate_ll_from_utm() requires zone datum columns. supports quoted unquoted column names user-specified datum lat/long coordinates. also adds extra column output data table documents lat/long coordinate reference system.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/generate_ll_from_utm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","text":"","code":"generate_ll_from_utm(   df,   EastingCol,   NorthingCol,   ZoneCol,   DatumCol,   latlong_datum = \"NAD83\" )"},{"path":"https://nationalparkservice.github.io/QCkit/reference/generate_ll_from_utm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","text":"df dataframe UTM coordinates like convert. Input name dataframe. EastingCol name Easting UTM column. may input name without quotations, ie. EastingCol \"EastingCol\" valid. NorthingCol name Northing UTM column. may input name without quotations, ie. NorthingCol \"NorthingCol\" valid. ZoneCol column containing UTM zone, without quotations. DatumCol column containing datum UTM coordinates, without quotations. latlong_datum datum use lat/long coordinates. Defaults NAD83.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/generate_ll_from_utm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","text":"function returns dataframe, mutated additional two columns decimalLongitude decimalLatitude plus column LatLong_CRS containing PROJ string specifies coordinate reference system data.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/generate_ll_from_utm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","text":"Define name dataframe, easting northing columns within , UTM zone within coordinates located, reference coordinate system (datum). UTM Northing Easting columns must separate columns prior running function. datum lat/long output defined, function default \"NAD83\". missing coordinates dataframe preserved, however moved end dataframe. Note parameter names snake_case instead reflect DarwinCore naming conventions. function uses tidy evaluation (.e. can provide column name arguments strings can leave unquoted). wish store column names strings variables, must enclose variables double curly braces pass function. See code examples .","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/generate_ll_from_utm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Conversion from UTM to Latitude and Longitude — generate_ll_from_utm","text":"","code":"if (FALSE) { # \\dontrun{  # Using magrittr pipe (%>%) and unquoted column names my_dataframe %>% generate_ll_from_utm(   EastingCol = UTM_X,   NorthingCol = UTM_Y,   ZoneCol = Zone,   DatumCol = Datum )  # Providing column names as strings (in quotes) generate_ll_from_utm(   df = mydataframe,   EastingCol = \"EastingCoords\",   NorthingCol = \"NorthingCoords\",   ZoneCol = \"zone\",   DatumCol = \"datum\",   latlong_datum = \"WGS84\" )  # Column names stored as strings in separate variables easting <- \"EastingCoords\" northing <- \"NorthingCoords\" zonecol <- \"zone\" datumcol <- \"datum\" latlong_dat <- \"WGS84\"  generate_ll_from_utm(   df = mydataframe,   EastingCol = {{easting}},  # enclose variables that store column names in {{}}   NorthingCol = {{northing}},   ZoneCol = {{zonecol}},   DatumCol = {{datumcol}},   latlong_datum = latlong_dat  # this isn't a column name so it doesn't need {{}} )  } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_custom_flags.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates dataframe(s) summarizing data quality — get_custom_flags","title":"Creates dataframe(s) summarizing data quality — get_custom_flags","text":"get_custom_flags returns data frames summarize data quality control flags (one summarizes data file level one column). summaries include data quality control flagging (column name ends \"_flag\") optionally additional custom columns user specifies, either column name number. use can specify 2 data frames (list dataframes) returned. number flag type column (, AE, R, P) reported. Unflagged columns assumed accepted (missing) data. total number data points specified columns (data flagging columns ) .csv also reported. NAs considered missing data. Unweighted Relative Response (RRU) calculated total number accepted data points (, AE, data flagged) divided total number data points (excluding missing values) specified columns (flagged columns).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_custom_flags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates dataframe(s) summarizing data quality — get_custom_flags","text":"","code":"get_custom_flags(   directory = here::here(),   cols = (\"\"),   output = c(\"all\", \"files\", \"columns\") )"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_custom_flags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates dataframe(s) summarizing data quality — get_custom_flags","text":"directory path data package .csv files (defaults current working directory). cols comma delimited list column names. left unspecified, defaults just flagged columns. output string indicating output provided. \"columns\" returns summary table QC flags RRU values specified column every data file. \"files\" returns summary table total QC flags mean across data file. \"\" return three data frames single list.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_custom_flags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates dataframe(s) summarizing data quality — get_custom_flags","text":"dataframe quality control summary information summarized specified level(s).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_custom_flags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates dataframe(s) summarizing data quality — get_custom_flags","text":"Flagged columns must names ending \"_flag\". Missing values must specified NA.  function counts cells within \"*_flag\" columns start one flagging characters (, AE, R, P) ignores trailing characters white spaces. custom columns include specific flagging column, non-missing (non-NA) values considered Accepted (). intent get_custom_flags integration reports data quality, Data Release Reports (DRRs).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_custom_flags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates dataframe(s) summarizing data quality — get_custom_flags","text":"","code":"if (FALSE) { # \\dontrun{  get_custom_flags(\"~/my_data_package_directory\", cols = c(\"scientificName\",                                                          \"locality\"),                                                          output=\"all\") cols <- colnames(read.csv(\"mydata.csv\"))[c(1:4, 7, 10)] get_custom_flags(cols = cols, output=\"files\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dc_flags.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","title":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","text":"get_dc_flags (dc=data columns) returns data frame , data file data package lists name data flagging column number flag type within column (, AE, R, P) well total number data points data flagging columns .csv, excluding NAs. Unweighted Relative Response (RRU) calculated total number accepted data points (, AE, data flagged).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dc_flags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","text":"","code":"get_dc_flags(directory = here::here())"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dc_flags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","text":"directory path data package .csv files (defaults current working directory).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dc_flags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","text":"dataframe named dc_flag contains row .csv file directory file name, count flag total number data points .csv (including data flagging columns).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dc_flags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","text":"function can run within working directory data package , directory can specified. function supports .csv files assumes data flagging columns column names ending \"_flag\". counts cells within columns start one flagging characters (, AE, R, P) ignores trailing characters whitespaces.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dc_flags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Table of Data Quality Flags in Flagging Columns within individual data columns — get_dc_flags","text":"","code":"if (FALSE) { # \\dontrun{ get_df_flags(\"~/my_data_package_directory\") get_df_flags() # if your current working directory IS the data package directory. # -> get_custom_flags(output=\"columns\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_df_flags.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","title":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","text":"get_df_flags (df = data files) returns data frame lists number cells data file entire data package (excluding NAs) relevant flags (, AE, R, P) well total number data points .csv (including data flagging columns, excluding NAs). Unweighted Relative Response (RRU) calculated total number accepted data points (, AE, data flagged).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_df_flags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","text":"","code":"get_df_flags(directory = here::here())"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_df_flags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","text":"directory path data package .csv files (defaults current working directory).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_df_flags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","text":"dataframe named df_flag contains row .csv file directory file name, count flag total number data points .csv (including data flagging columns).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_df_flags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","text":"function can run within working directory data package , directory can specified. function supports .csv files assumes .csv files folder part data package. also assumes values , AE, R, P used flagging. assumes additional characters flagging cells (leading trailing white spaces).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_df_flags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Table of Data Quality Flags Found in Data Files within a Data Package — get_df_flags","text":"","code":"if (FALSE) { # \\dontrun{ get_df_flags(\"~/my_data_package_directory\") get_df_flags() # if your current working directory IS the data package directory. # -> get_custom_flags(output=\"files\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dp_flags.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","title":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","text":"get_dp_flags (dp=data package) returns data frame list number cells entire data package relevant flags (, AE, R, P) well total number non-NA cells data package (including data flagging columns). Unweighted Relative Response (RRU) calculated total number accepted data points (, AE, data flagged).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dp_flags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","text":"","code":"get_dp_flags(directory = here::here())"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dp_flags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","text":"directory path data package .csv files (defaults current working directory).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dp_flags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","text":"dataframe named dp_flag contains four flags, count flag total number data points entire data package.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dp_flags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","text":"function can run within working directory data package , directory can specified. function supports .csv files assumes .csv files folder part data package. function counts cells within \"*_flag\" columns start one flagging characters (, AE, R, P) ignores trailing characters whitespaces. NAs assumed empty cells missing data.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_dp_flags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Table of Data Quality Flags Found in a Data Package — get_dp_flags","text":"","code":"if (FALSE) { # \\dontrun{ get_dp_flags(\"~/my_data_package_directory\") get_dp_flags() # if your current working directory IS the data package directory. # -> get_custom_flags(output=\"package\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_elevation.html","id":null,"dir":"Reference","previous_headings":"","what":"Add elevation to a dataset — get_elevation","title":"Add elevation to a dataset — get_elevation","text":"get_elevation() takes dataframe includes GPS coordinates (decimal degrees) returns dataframe two new columns added , minimumElevationInMeters maximumElevationInMeters. function requires data supplied numeric missing values specified NA.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_elevation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add elevation to a dataset — get_elevation","text":"","code":"get_elevation(   df,   decimal_lat,   decimal_long,   spatial_ref = c(4326, 102100),   force = FALSE )"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_elevation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add elevation to a dataset — get_elevation","text":"df data frame containing GPS decimal coordinates individual points latitude longitude separate columns. decimal_lat String. name column containing longitudes decimal_long String. name column containing latitudes spatial_ref Categorical. Defaults 4326. Can also set 102100. force Logical. Defaults FALSE. Returns verbose comments, interactions, information. Set TRUE remove interactive components reduce/remove comments informative print statements.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_elevation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add elevation to a dataset — get_elevation","text":"data frame two new columns, minimumElevationInMeters maximumElevationInMeters","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_elevation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add elevation to a dataset — get_elevation","text":"get_elevation() uses USGS API National Map identify elevevation given set GPS coordinates. reduce API queries (time completion), function search unique GPS coordinates dataframe. take time. lots GPS coordinates, can also perform manual bulk upload (maximum = 500 points). Note new columns (minimumElevationInMeters maximumElevationInMeters) contain elevation; expected behavior single GPS coordinate maximum minimum elevations. column names generated accordance simple Darwin Core Standards. Points outside US may return NA values part National Map.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_elevation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add elevation to a dataset — get_elevation","text":"","code":"if (FALSE) { # \\dontrun{ new_dataframe <- get_elevation(df,                               \"decimalLatitude\",                               \"decimalLongitude\",                               spatial_ref=\"4326\") new_dataframe <- get_elevation(df,                               \"decimalLatitude\",                               \"decimalLongitude\",                               spatial_ref=\"102100\",                               force=TRUE)  } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_park_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the polygon information for the park unit from NPS REST services — get_park_polygon","title":"Retrieve the polygon information for the park unit from NPS REST services — get_park_polygon","text":"get_park_polygon() retrieves geoJSON string polygon park unit. official boundary. Note REST API call returns default \"convexHull\". work better worse parks, depending park shape/geography/number disjunct areas. #'","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_park_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the polygon information for the park unit from NPS REST services — get_park_polygon","text":"","code":"get_park_polygon(unit_code)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_park_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the polygon information for the park unit from NPS REST services — get_park_polygon","text":"unit_code four-character unit code designated NPS.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_park_polygon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the polygon information for the park unit from NPS REST services — get_park_polygon","text":"","code":"if (FALSE) { # \\dontrun{ qc_getParkPolygon(\"OBRI\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_taxon_rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Taxonomic Rank Determination Function — get_taxon_rank","title":"Taxonomic Rank Determination Function — get_taxon_rank","text":"get_taxon_rank() generates new column selected data set called taxonRank show taxonomic rank specific name given scientific name column. required column Simple Darwin Core rule set guidelines. function useful creating auto populating required Simple Darwin Core field.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_taxon_rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Taxonomic Rank Determination Function — get_taxon_rank","text":"","code":"get_taxon_rank(df, sciName_col)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_taxon_rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Taxonomic Rank Determination Function — get_taxon_rank","text":"df name data frame containing species observations sciName_col name column within data frame containing scientific names species.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_taxon_rank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Taxonomic Rank Determination Function — get_taxon_rank","text":"function returns new column given data frame named taxonRank taxonomic rank corresponding scientific name column. name row, returns NA row.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_taxon_rank.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Taxonomic Rank Determination Function — get_taxon_rank","text":"Define species data set name column name scientific names species (following Simple Darwin Core naming format, column scientificName, column name fine). function read various strings species name column identify either family, genus, species, subspecies. function works cleaned parsed scientific names. scientific name higher family, function work correctly. Subfamily Tribe names (, similar family names end \"ae*\") designated Family.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_taxon_rank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Taxonomic Rank Determination Function — get_taxon_rank","text":"","code":"if (FALSE) { # \\dontrun{ mydf <- get_taxon_rank(df = mydf, sciName_col = \"scientificName\") } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_utm_zone.html","id":null,"dir":"Reference","previous_headings":"","what":"Return UTM Zone — get_utm_zone","title":"Return UTM Zone — get_utm_zone","text":"get_utm_zone() replaces convert_long_2_utm() function name descriptive. get_utm_zone() takes longitude coordinate returns corresponding UTM zone.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_utm_zone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return UTM Zone — get_utm_zone","text":"","code":"get_utm_zone(lon)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_utm_zone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return UTM Zone — get_utm_zone","text":"lon Decimal degree longitude value","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_utm_zone.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return UTM Zone — get_utm_zone","text":"function returns numeric UTM zone (1 60).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/get_utm_zone.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return UTM Zone — get_utm_zone","text":"Input longitude (decimal degree) coordinate simple function returns number UTM zone point falls.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/long2UTM.html","id":null,"dir":"Reference","previous_headings":"","what":"Return UTM Zone — long2UTM","title":"Return UTM Zone — long2UTM","text":"long2UTM deprecated favor convert_long_to_utm() enforce consistent function naming pattern across package conform tidyverse style guide. long2UTM() take longitude coordinate returns corresponding UTM zone.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/long2UTM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return UTM Zone — long2UTM","text":"","code":"long2UTM(lon)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/long2UTM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return UTM Zone — long2UTM","text":"lon Decimal degree longitude value","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/long2UTM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return UTM Zone — long2UTM","text":"function returns numeric UTM zone (1 60).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/long2UTM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return UTM Zone — long2UTM","text":"Input longitude (decimal degree) coordinate simple function returns number UTM zone point falls.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/order_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Ordering Columns Function 03-21-2023 — order_cols","title":"Ordering Columns Function 03-21-2023 — order_cols","text":"order_cols() Checks orders columns TDWG Darwin Core naming standards custom names dataset","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/order_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ordering Columns Function 03-21-2023 — order_cols","text":"","code":"order_cols(df)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/order_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ordering Columns Function 03-21-2023 — order_cols","text":"df dataframe want run function. call, simply type df = \"name dataframe\".","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/order_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ordering Columns Function 03-21-2023 — order_cols","text":"function returns list required suggested columns include dataset. assigning object, object contains new dataset columns ordered properly.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/order_cols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ordering Columns Function 03-21-2023 — order_cols","text":"Check see three (highly) recommended columns (locality, type, basisOfRecord) various suggested columns present dataset. Print list columns present . , order columns dataset following order: (highly) recommended columns, suggested columns, rest Darwin Core columns, \"custom_\" (non-Darwin Core) columns, finally sensitive species data columns. columns darwinCore term names, start \"custom_\" \"scientificName_flag\" placed darwinCore columns \"custom_\" columns. One exception dataset includes column custom_TaxonomicNotes, placed directly namePublishedIn, column exists. Suggested darwinCore column names (plus scientificName_flag) include (order placed): eventDate, eventDate_flag, scientificName, scientificName_flag, taxonRank, verbatimIdentification, vernacularName, namePublishedIn, recordedBy, individualCount, decimalLongitude, decimalLatitude, coordinate_flag, geodeticDatum\", verbatimCoordinates, verbatimCoordinateSystem, verbatimSRS,coordinateUncertaintyInMeters. Note suggested names include custom, non-Darwin Core names \"scientificName_flag\". sensitive species data columns defined : informationWithheld, dataGeneralizations, footprintWKT.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/order_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ordering Columns Function 03-21-2023 — order_cols","text":"","code":"if (FALSE) { # \\dontrun{ order_cols(df) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/remove_empty_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove empty tables from a list — remove_empty_tables","title":"Remove empty tables from a list — remove_empty_tables","text":"Remove empty tables list","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/remove_empty_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove empty tables from a list — remove_empty_tables","text":"","code":"remove_empty_tables(df_list)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/remove_empty_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove empty tables from a list — remove_empty_tables","text":"df_list list tibbles dataframes.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/remove_empty_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove empty tables from a list — remove_empty_tables","text":"list empty tables removed.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/remove_empty_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove empty tables from a list — remove_empty_tables","text":"","code":"test_list <- list(item_a = tibble::tibble,                   item_b = mtcars,                   item_c = iris)  tidy_list <- remove_empty_tables(test_list)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/replace_blanks.html","id":null,"dir":"Reference","previous_headings":"","what":"Replaces all blank cells a missing value code of your choice — replace_blanks","title":"Replaces all blank cells a missing value code of your choice — replace_blanks","text":"replace_blanks() particularly useful exporting data database (access) converting data package metadata. replace_blanks() import .csv files specified working directory. files written back directory, overwriting old .csv files. blank cells (cells \"NA\" original .csv files) replaced specified string integer. missing value specified, function defaults replacing blanks \"NA\". Please keep mind \"missing\" general term data present data file data package. Although may good reason providing data data may , data package creator's perspective, \"missing\" (maybe never intended collect ) data package user's perspective data data package effectively \"missing\" data package. Therefore, critical document metadata data absent appropriate \"missingValueCode\" \"missingValueDefinition\". terms defined metadata schema broadly used apply data present. function replace empty cells cells NA \"missingValueCode\" choice (although defaults NA).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/replace_blanks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replaces all blank cells a missing value code of your choice — replace_blanks","text":"","code":"replace_blanks(directory = here::here(), missing_val_code = NA)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/replace_blanks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replaces all blank cells a missing value code of your choice — replace_blanks","text":"directory String. Path file(s) blanks replaced NAs. Defaults working directory project (::()) missing_val_code String, integer, double, float. Defaults NA.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/replace_blanks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replaces all blank cells a missing value code of your choice — replace_blanks","text":"list data frames (invisibly)","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/replace_blanks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replaces all blank cells a missing value code of your choice — replace_blanks","text":"One exception .csv contains data (.e. just column names data cells). case, blanks replaced NA (function determine many NAs include).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/replace_blanks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replaces all blank cells a missing value code of your choice — replace_blanks","text":"","code":"if (FALSE) { # \\dontrun{ #replaces all blank cells in .csvs in the current directory with NA:  replace_blanks()  #replace all blank cells in .csvs in the directory ./test_data with \"NODATA\"  dir <- here::here(\"test_data\")  replace_blanks(directory = dir, missing_val_code = \"NODATA\")  #replace all blank cells in .csvs in the current directory with -99999 replace_blanks(missing_val_code = -99999) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/te_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Threatened Or Endangered Species Checker Function — te_check","title":"Threatened Or Endangered Species Checker Function — te_check","text":"function deprecated favor check_te(). function name changed promote constancy function naming across package conform tidyverse style guides. te_check() longer updated may reference latest version federal endangered threatened species listings. te_check() generates list species consider removing dataset making public matching scientific names within data set Federal Conservation List. te_check() considered helpful tool identifying federally listed endangered threatened species data. National Park park-specific Protected Data Memo outlines data restricted. Threatened endangered species often - although always - listed Memos. Additional species (state conservation lists) non-threatened non-endangered species concern biological non-biological resources may listed Memos. Consult relevant park-specific Protected Data Memo prior making decisions restricting releasing data.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/te_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threatened Or Endangered Species Checker Function — te_check","text":"","code":"te_check(x, species_col, park_code, expansion = FALSE)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/te_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Threatened Or Endangered Species Checker Function — te_check","text":"x name data frame containing species observations species_col name column within data frame containing scientific names species (genus specific epithet). park_code four letter park code. list park codes. expansion Logical. Defaults FALSE. default setting return exact matches scientific binomial (genera specific epithet) data set federal match list. Setting expansion = TRUE expand list matches return species (subspecies) match list match genera listed data set, regardless whether given species actually data set. additional column indicating whether species returned data set (\"Data\") expanded (\"Expansion\") generated.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/te_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Threatened Or Endangered Species Checker Function — te_check","text":"function returns (modified) data frame names species fall federal conservation list. resulting data frame may multiple instances given species listed multiple parks (park codes listing supplied). Technically huxtable, function identically data frame downstream purposes.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/te_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Threatened Or Endangered Species Checker Function — te_check","text":"Define species data set name, column name scientific names species, four letter park code. te_check() function downloads Federal Conservation list using IRMA odata API service matches species list list scientific names data frame. Keep mind Federal list, state list. Changes taxa names may also cause species missed. odata API service publicly available, must logged NPS VPN office use function. default, expansion = FALSE, function perform exact match taxa scientificName column federal Conservation List filter results keep species listed endangered, threatened, considered listing. scientificName column contains information binomial (genus species), matches returned. instance, Order just genus listed, matched Federal Conservation List. set expansion = TRUE, function truncate item scientificName column first word attempt extract genus name. genera listed, retained. higher-order taxa listed Family, Order, Phyla first word retained. first word (typically genus) matched just generic name species Federal Conservation List. matches, regardless listing status, retained. result given species scientificName column, species within genus Federal Conservation List returned (along federal conservation listing codes column indicating whether species actually data part expanded search).","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/te_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Threatened Or Endangered Species Checker Function — te_check","text":"","code":"if (FALSE) { # \\dontrun{ #for individual parks: te_check(x = my_species_dataframe, species_col = \"scientificName\", park_code = \"BICY\") list<-te_check(data, \"scientificName\", \"ROMO\", expansion=TRUE) # for a list of parks: park_code<-c(\"ROMO\", \"YELL\", \"SAGU\") list<-te_check(data, \"scientificName\", park_code, expansion=TRUE) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/unit_codes_to_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts unit codes to full unit (park) names — unit_codes_to_names","title":"Converts unit codes to full unit (park) names — unit_codes_to_names","text":"unit_code_to_names takes single unit code vector unit codes returns data frame full unit names using public IRMA API. example given code \"ROMO\" function return \"Rocky Mountain National Park\".","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/unit_codes_to_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts unit codes to full unit (park) names — unit_codes_to_names","text":"","code":"unit_codes_to_names(unit_code)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/unit_codes_to_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts unit codes to full unit (park) names — unit_codes_to_names","text":"unit_code string list strings consisting (typically) four-letter unit codes.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/unit_codes_to_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts unit codes to full unit (park) names — unit_codes_to_names","text":"data frame consisting single column full park names","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/unit_codes_to_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts unit codes to full unit (park) names — unit_codes_to_names","text":"","code":"if (FALSE) { # \\dontrun{  unit_codes_to_names(\"ROMO\")  unit_codes_to_names(c(\"ROMO\", \"GRYN\"))  } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/utm_to_ll.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","title":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","text":"utm_to_ll() deprecated favor convert_utm_to_ll() enforce consistent naming scheme functions across package conform tidyverse style guide. utm_to_ll takes dataframe UTM coordinates separate Easting Northing columns, adds additional two columns converted decimalLatitude decimalLongitude coordinates using reference coordinate system WGS84.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/utm_to_ll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","text":"","code":"utm_to_ll(df, EastingCol, NorthingCol, zone, datum = \"WGS84\")"},{"path":"https://nationalparkservice.github.io/QCkit/reference/utm_to_ll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","text":"df dataframe UTM coordinates like convert. Input name dataframe. EastingCol name Easting UTM column. Input name quotations, ie. \"EastingCol\". NorthingCol name Northing UTM column. Input name quotations, ie. \"NorthingCol\". zone UTM Zone. Input zone number quotations, ie. \"17\". datum datum used coordinate reference system coordinates. Input quotations, ie. \"WGS84\"","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/utm_to_ll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","text":"function returns dataframe, mutated additional two columns decimal Longitude decimal Latitude.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/utm_to_ll.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","text":"Define name dataframe, easting northing columns within , UTM zone within coordinates located, reference coordinate system (datum). UTM Northing Easting columns must separate columns prior running function. datum defined, function default \"WGS84\". missing coordinates dataframe preserved, however moved end dataframe. Note parameter names snake_case instead reflect DarwinCore naming conventions.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/utm_to_ll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Conversion from UTM to Latitude and Longitude — utm_to_ll","text":"","code":"if (FALSE) { # \\dontrun{ utm_to_ll(   df = mydataframe,   EastingCol = \"EastingCoords\",   NorthingCol = \"NorthingCoords\",   zone = \"17\",   datum = \"WGS84\" ) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether a coordinate pair is within the polygon of a park unit — validate_coord","title":"Check whether a coordinate pair is within the polygon of a park unit — validate_coord","text":"validate_coord() compares coordinate pair (decimal degrees) polygon park unit provided NPS Units rest services. function returns value TRUE FALSE.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether a coordinate pair is within the polygon of a park unit — validate_coord","text":"","code":"validate_coord(unit_code, lat, lon)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether a coordinate pair is within the polygon of a park unit — validate_coord","text":"unit_code four-character unit code designated NPS. lat latitude, decimal degrees. lon longitude, decimal degrees.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether a coordinate pair is within the polygon of a park unit — validate_coord","text":"","code":"if (FALSE) { # \\dontrun{ validate_coord(\"OBRI\", 36.07951, -84.65610) } # }"},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether decimal GPS coordinates are inside a park unit — validate_coord_list","title":"Test whether decimal GPS coordinates are inside a park unit — validate_coord_list","text":"function can take list coordinates park units input. addition vectorized, depending park borders, can major improvement validate_coord().","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether decimal GPS coordinates are inside a park unit — validate_coord_list","text":"","code":"validate_coord_list(lat, lon, park_units)"},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether decimal GPS coordinates are inside a park unit — validate_coord_list","text":"lat numeric. individual vector numeric values representing decimal degree latitude coordinate lon numeric. individual vector numeric values representing decimal degree longitude coordinate park_units String. list strings containing four letter park unit designation","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether decimal GPS coordinates are inside a park unit — validate_coord_list","text":"logical","code":""},{"path":"https://nationalparkservice.github.io/QCkit/reference/validate_coord_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether decimal GPS coordinates are inside a park unit — validate_coord_list","text":"","code":"if (FALSE) { # \\dontrun{ x <- validate_coord_list(lat = 105.555, long = -47.4332, park_units = \"DRTO\")  # or a dataframe with many coordinates and potentially many park units: x <- validate_coord_list(lat = df$decimalLatitutde,                 lon = df$decimalLongitude,                 park_units = df$park_units) # you can then merge it back in to the original dataframe: df$test_GPS_coord <- x } # }"},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"id_2025-1-0-2","dir":"Changelog","previous_headings":"","what":"2025-05-16","title":"QCkit v1.0.2 (development version)","text":"create_datastore_script now invisibly returns DataStore reference URL","code":""},{"path":[]},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"id_2025-1-0-1","dir":"Changelog","previous_headings":"","what":"2025-03-25","title":"QCkit v1.0.1","text":"fix bug caused several functions fail detect certain .csv files 2025-03-12 * Updated license MIT JOSS, NPS, R compatible! 2025-03-10 * Updated license OSI-approved “Zero-Clause BSD” support JOSS submission. 2025-03-06 * Begin development unit_codes_to_names function translate NPS unit codes full unit (park) names * Add basic unit test unit_codes_to_names 2025-02-25 * Updated CONTRIBUTING.md. 2025-02-21 * Add CONTRIBUTING.md file","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-v100","dir":"Changelog","previous_headings":"","what":"QCkit v1.0.0","title":"QCkit v1.0.0","text":"2024-07-16 * Added experimental function document_missing_values(), searches file multiple missing value codes, replaces NA, generates new column missing value codes can properly documented EML. work-around fact currently good way get multiple missing value codes single column via EMLassemblyline. function still development; expect substantial changes improvements including removing function entirely. 2024-07-09 * Added function get_user_email(), accesses NPS active directory via powershell function return user’s email address. Probably won’t work non-NPS users probably won’t work non-windows users. * Updated rest API legacy v6 current v7. 2024-06-28 * Updated get_park_polygon() use new API (using legacy API). Added documentation specify function getting convexhull park, may work particularly well parks. 2024-06-27 * bug fixes generate_ll_from_utm() * add function remove_empty_tables() (associated unit tests) * update documentation replace blanks() indicate can replace blanks just NA","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-v017","dir":"Changelog","previous_headings":"","what":"QCkit v0.1.7","title":"QCkit v0.1.7","text":"2024-05-08 * Updated replace_blanks() function accept missing value code user inputs (still defaults NA). 2024-04-18 * Added function generate_ll_from_utm() supersedes convert_utm_to_ll() improves upon several ways, included accepting column UTMs also returns column CRS along decimal degrees latitude longitude. 2024-04-17 * Major updates DRR template including: using snake case instead camel case variables; updating Table 3 display filenames multiple files, fixed multiple issues footnotes, added citations NPSdataverse packages, added section prints R code needed download data package load R. * Updated DRR documentation account new variable names.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-v016","dir":"Changelog","previous_headings":"","what":"QCkit v0.1.6","title":"QCkit v0.1.6","text":"2024-03-07 * Update error warning check_te() reference VPN since NPS longer uses VPN. * add private function .get_unit_bondaries(): hits ArcGIS API pull precise park unit boundaries get_park_polgyon() * add validate_coord_list() function takes advantage improved precision .get_unit_boundaries() vectorized, enabling users input multiple coordinate combinations park units directly data frame.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-v015","dir":"Changelog","previous_headings":"","what":"QCkit v0.1.5","title":"QCkit v0.1.5","text":"2024-02-09 * version adds DRR template, example files, associated documentation QCkit package. * Bugfix get_custom_flag(): counting (accepted) AE (Accepted, estimated) Accepted. Fixed regex Accepted include cells start followed nothing character except AE flags can explanation codes added (e.g. A_jenkins “Jenkins” flagged data accepted)","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-v014","dir":"Changelog","previous_headings":"","what":"QCkit v0.1.4","title":"QCkit v0.1.4","text":"2024-01-23 * Maintenance get_custom_flag() align updated DRR requirements * Added function replace_blanks() ingest directory .csvs write back .csv (overwriting original files) blanks converted NA (except file data - remains blank needs dealt manually)","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-012-automated-shuttle-pilot","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.2 “Automated Shuttle Pilot”","title":"QCkit 0.1.2 “Automated Shuttle Pilot”","text":"2023-11-20 * Added function create_datastore_scipt(), given username repo GitHub generate draft Script Reference DataStore based information found latest Release GitHub. 24 April 2023 * fixed bug get_custom_flags().","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-0104","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.0.4","title":"QCkit 0.1.0.4","text":"17 April 2023 get_elevation() new function getting elevation GPS coordinates via USGS API. 21 March 2023 order_cols new function ordering columns added 16 March 2023 Added new function, get_taxon_rank() takes column scientific names generates new column specific scientific name rank listed. purely based recognizing patterns scientific naming scheme matching list known genera, families, etc. Consolidated get_taxon_rank() te_check() single file, taxonomy.R. Deprecated te_check() favor check_te() Deprecated DC_col_check() favor check_dc_cols() Deprecated utm_to_ll() favor convert_utm_to_ll() Deprecated long2UTM() favor convert_long_to_utm()","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-0103","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.0.3","title":"QCkit 0.1.0.3","text":"28 February 2023 te_check() bug fix - exact column name filtering allows multiple columns similar names input data column. Improved documentation transparency. 23 February 2023 updated te_check(). now supports searching multiple park units. 22 February 2023 updated te_check(). Now prints source federal match list data date accessed console. Made output format prettier. Added “expansion” option function. Defaults expansion = FALSE, checks exact matches scientific binomial supplied user full scientific binomial matchlist. expansion = TRUE, genera data supplied checked matchlist species given genera returned, regardless whether given species actually supplied data set. new column “InData” tell user whether given species actually data expanded .","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-0102","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.0.2","title":"QCkit 0.1.0.2","text":"02 February 2023 Fixed major bug te_check() causing function return species threatened endangered. function now returns tibble containing species threatened, endangered, considered listing, specifies status code species, give brief explanation federal endangered species act status code returned.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-0102-1","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.0.2","title":"QCkit 0.1.0.2","text":"Marked get_custom_flags() experimental. Removed “force” option removed final print statement Reduced number summary columns reported fixed RRU calculation (+AE)/(+AE+P+R+NA) instead (+E)/(+AE+P+R)","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-0101","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.0.1","title":"QCkit 0.1.0.1","text":"get_dp_flags() returns counts data flag (, AE, R, P) across whole data package (well cells data package). get_df_flags() returns counts data flags within data file data package (well counts cells within data package). get_dc_flags() returns name flagging column within data package count flag within column well total number cells across data flagging columns. function force option defaults force = FALSE prints results screen. setting force = TRUE suppress -screen output.","code":""},{"path":"https://nationalparkservice.github.io/QCkit/news/index.html","id":"qckit-0100","dir":"Changelog","previous_headings":"","what":"QCkit 0.1.0.0","title":"QCkit 0.1.0.0","text":"Added NEWS.md file track changes package.","code":""}]
